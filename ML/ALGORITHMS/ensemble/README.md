앙상블 학습(Ensemble Learning)은 여러 개의 분류기를 생성하고, 그 예측을 결합함으로써 보다 정확한 예측을 도출하는 기법을 말합니다. 머신러닝에서의 앙상블 모델은 "여러 모델이 동일한 문제를 해결하고 더 나은 결과를 얻도록 훈련시키는 기계 학습 패러다임"을 기반으로 만들어진 모델입니다. 앙상블 예측 방법은 예측기가 가능한 한 서로 독립적일 때 최고의 성능을 발휘합니다. 다양한 분류기를 얻는 한 가지 방법은 각기 다른 알고리즘으로 학습시키는 것입니다. 이렇게 하면 매우 다른 종류의 오차를 만들 가능성이 높기 때문에 앙상블 모델의 정확도를 향상시킵니다.

Overfitting이 문제다 → Bagging
Accuracy가 문제다 → Boosting

**장점:**

- 과적합(Overfitting) 감소 효과가 있습니다.
- 개별 모델 성능이 잘 안 나올 때 이용하면 성능이 향상될 수 있습니다.

**단점:**

- 예측 시간이 많이 소요됩니다.
- 모델 결과의 해석이 어렵습니다.

---

## 투표 기반 분류기(Voting)

여러 개의 분류기가 투표를 통해 최종 예측 결과를 결정하는 방식입니다. 서로 다른 알고리즘을 여러 개 결합하여 사용합니다.

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ea6fef7b-9a8f-47ca-9871-d84068e48eac/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ea6fef7b-9a8f-47ca-9871-d84068e48eac/Untitled.png)

### 직접 투표(Hard voting) 분류기

각 분류기의 예측을 모아서 가장 많이 선택된 클래스를 예측합니다. 각 분류기가 약한 학습기(weak learner)[랜덤 추측보다 조금 더 높은 성능을 내는 분류기]일지라도 충분하게 많고 다양하다면 앙상블은 (높은 정확도를 내는) 강한 학습기(strong learner)가 될 수 있습니다.

### 간접 투표(Soft voting) 분류기

모든 분류기가 클래스의 확률을 예측할 수 있으면(코드 상에선 `predict_proba()` 메서드가 있으면), 개별 분류기의 예측을 평균 내어 확률이 가장 높은 클래스를 예측할 수 있습니다. 이를 간접 투표라고 합니다. 이 방식은 확률이 높은 투표에 비중을 더 두기 때문에 직접 투표 방식보다 성능이 높습니다.

---

## 배깅과 페이스팅(Bagging and Pasting)

배깅 → 분산 최소화

같은 알고리즘을 사용하는 경우에는 Training Set을 무작위로 구성하여 분류기를 각기 다르게 학습시키는 방법이 있습니다. Training Set에서 **중복을 허용하여 샘플링**하는 방식을 **배깅(Bootstrap Aggregating)**이라 하며, **중복을 허용하지 않고 샘플링**하는 방식을 **페이스팅(Pasting)**이라고 합니다.

모든 예측기가 학습을 마치면 앙상블은 모든 예측기의 예측을 모아서 새로운 샘플에 대한 예측을 만듭니다. 수집 함수는 전형적으로 분류일 때는 통계적 최빈값(Statistical Mode)(즉, 직접 투표 분류기처럼 가장 많은 예측 결과)이고 회귀에 대해서는 평균을 계산합니다. 개별 예측기는 원본 Training Set으로 훈련시킨 것보다 훨씬 크게 편향되어 있지만 수집 함수를 통과하면 편향과 분산이 모두 감소합니다. 일반적으로 앙상블의 결과는 원본 데이터셋으로 하나의 예측기를 학습시킬 때와 비교해 편향은 비슷하지만 분산은 줄어듭니다.

예측기는 모두 동시에 다른 CPU 코어나 서버에서 병렬로 학습시킬 수 있습니다. 이와 유사하게 예측도 병렬로 수행할 수 있습니다. 이런 확장성 덕분에 배깅과 페이스팅의 인기가 높습니다.

부트스트래핑은 각 예측기가 학습하는 서브셋에 다양성을 증가시키므로 배깅이 페이스팅보다 편향이 조금 더 높습니다. 하지만 다양성을 추가한다는 것은 예측기들의 상관관계를 줄이므로 앙상블의 분산을 감소시킵니다. 전반적으로 배깅이 더 나은 모델을 만들기 때문에 일반적으로 더 선호합니다. 그러나 시간과 CPU 파워에 여유가 있다면 교차 검증으로 배깅과 페이스팅을 모두 평가해서 더 나은 쪽을 선택하는 것이 좋습니다.

## oob 평가

배깅을 사용하면 어떤 샘플은 한 예측기를 위해 여러 번 샘플링되고 어떤 것은 전혀 선택되지 않을 수 있습니다. `BaggingClassifier` 는 기본값으로 중복을 허용하여(`bootstrap=True`) 훈련 세트의 크기만큼인 $m$개 샘플을 선택합니다. 이는 평균적으로 각 예측기에 훈련 샘플의 63% 정도만 사용된다는 것을 의미합니다. [[참고]](https://goo.gl/ifFbg3) 선택되지 않은 훈련 샘플의 나머지는 37%를 oob(out-of-bag) 샘플이라고 부릅니다.

예측기가 훈련되는 동안에는 oob 샘플을 사용하지 않으므로 별도의 검증 세트를 사용하지 않고 oob 샘플을 사용해 평가할 수 있습니다. 앙상블의 평가는 각 예측기의 oob 평가를 평균하여 얻습니다.

---

## 랜덤 패치와 랜덤 서브스페이스

특성에 대한 샘플링으로, 각 예측기는 무작위로 선택한 입력 특성의 일부분으로 훈련됩니다. 이 기법은 매우 고차원의 데이터셋을 다룰 때 유용합니다.

훈련 특성과 샘플을 모두 샘플링하는 것을 랜덤 패치 방식이라고 합니다. 훈련 샘플을 모두 사용하고 특성은 샘플링하는 것을 랜덤 서브스페이스 방식이라고 합니다.

특성 샘플링은 더 다양한 예측기를 만들며 편향을 늘리는 대신 분산을 낮춥니다.

---

## 부스팅(Boosting)

부스팅 → 성능 자체를 강화, 즉 편향이 높은 경우 이를 낮추기 위해서 많이 사용

부스팅(Boosting; 가설 부스팅(hypothesis boosting)이라고 불린)은 약한 학습기를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법을 말합니다. 부스팅 방법의 아이디어는 앞의 모델을 보완해나가면서 일련의 예측기를 학습시키는 것입니다. 부스팅 방법에는 여러 가지가 있지만 가장 인기 있는 것은 에이다부스트(Adaboost; adaptive boosting)와 그레이디언트 부스팅(gradient boosting)입니다.

두 기법 모두 연속된 학습 기법입니다. 경사 하강법은 비용 함수를 최소화하기 위해 한 예측기의 모델 파라미터를 조정해가는 반면 에이다부스트는 점차 더 좋아지도록 앙상블에 예측기를 추가합니다.

연속된 학습 기법에는 중요한 단점이 하나 있습니다. 각 예측기는 이전 예측기가 훈련되고 평가된 후에 학습될 수 있기 때문에 병렬화(또는 분할)를 할 수 없습니다. 결국 배깅이나 페이스팅만큼 확장성이 높지 않습니다.

---

## 스태킹(Stacking)

Stacked generalization의 줄임말입니다. 이는 '앙상블에 속한 모든 예측기의 예측을 취합하는 간단한 함수를 사용하는 대신 취합하는 모델을 훈련시킬 수 없을까요?'라는 기본 아이디어로 출발합니다. 예측기들은 각각 값을 예측하고 마지막 예측기(Blender or Meta learner)가 이 예측을 입력으로 받아 최종 예측을 만듭니다.

블렌더를 학습시키는 일반적인 방법은 홀드 아웃(hold-out) 세트를 이용하는 것입니다. 첫 번째 서브셋은 첫 번째 레이어의 예측을 훈련시키기 위해 사용됩니다. 그런 다음 첫 번째 레이어의 예측기를 사용해 두 번째 세트에 대한 예측을 만듭니다. 예측기들이 훈련하는 동안 이 샘플들을 전혀 보지 못했기 때문에 이때 만들어진 예측은 완전히 새로운 것입니다. 

---

### Random Forest 란?

일반적으로 배깅 방법을 적용한 결정 트리의 앙상블입니다. 랜덤 포레스트 알고리즘은 트리의 노드를 분할할 때 전체 특성 중에서 최선의 특성을 찾는 대신 무작위로 선택한 특성 후보 중에서 최적의 특성을 찾는 식으로 무작위성을 더 주입합니다. 이는 결국 트리를 더욱 다양하게 만들고 편향을 손해보는 대신 분산을 낮추어 전체적으로 더 훌륭한 모델을 만들어냅니다. 

### Extra-Trees 란?

랜덤 포레스트에서 트리를 만들 때 각 노드는 무작위로 특성의 서브셋을 만들어 분할에 사용합니다. 트리를 더욱 무작위하게 만들기 위해 최적의 임계값을 찾는 대신 후보 특성을 사용해 무작위로 분할한 다음 그중에서 최상의 분할을 선택합니다.

이와 같이 극단적으로 무작위한 트리의 랜덤 포레스트를 익스트림 랜덤 트리(Extremely Randomized Tree) 앙상블(또는 줄여서 Extra-trees)이라고 부릅니다. 여기서도 역시 편향이 늘어나지만 대신 분산을 낮추게 됩니다. 모든 노드에서 특성마다 가장 최적의 임곗값을 찾는 것이 트리 알고리즘에서 가장 시간이 많이 소요되는 작업 중 하나이므로 일반적으로 랜덤 포레스트보다 엑스트라 트리가 훨씬 빠릅니다.

### 특성 중요도

랜덤 포레스트의 또 다른 장점은 특성의 상대적 중요도를 측정하기 쉽다는 것입니다. 사이킷런은 어떤 특성을 사용한 노드가 평균적으로 불순도를 얼마나 감소시키는지 확인하여 특성의 중요도를 측정합니다. 더 정확히 말하면 가중치 평균이며 각 노드의 가중치는 연관된 훈련 샘플 수와 같습니다. 결정 트리의 특성 중요도는 사용된 특성별로 (현재 노드의 샘플 비율 $\times$ 불순도) $-$ (왼쪽 자식 노드의 샘플 비율 $\times$ 불순도) $-$ (오른쪽 자식 노드의 샘플 비율 $\times$ 불순도)와 같이 계산하여 더하고, 특성 중요도의 합이 1이 되도록 전체 합으로 나누어 정규화합니다. 여기서 샘플 비율은 트리 전체 샘플 수에 대한 비율입니다. 랜덤 포레스트의 특성 중요도는 각 결정 트리의 특성 중요도를 모두 계산하여 더한 후 트리 수로 나눈 것입니다.

---

### Adaboost

이전 예측기를 보완하는 새로운 예측기를 만드는 방법은 이전 모델이 Underfitting했던 훈련 샘플의 가중치를 더 높이는 것입니다. 이렇게 하면 새로운 예측기는 학습하기 어려운 샘플에 점점 더 맞춰지게 됩니다. 이것이 에이다부스트에서 사용하는 방식입니다.

예를 들어 에이다부스트 분류기를 만들 때 먼저 알고리즘이 기반이 되는 첫 번째 분류기를 훈련 세트에서 훈련시키고 예측을 만듭니다. 그다음에 알고리즘이 잘못 분류된 훈련 샘플의 가중치를 상대적으로 높입니다. 두 번째 분류기는 업데이트된 가중치를 사용해 훈련 세트에서 훈련하고 다시 예측을 만듭니다. 그다음에 다시 가중치를 업데이트하는 식으로 계속됩니다.

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6d9badf8-63b6-4f80-97c9-3d4751570818/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6d9badf8-63b6-4f80-97c9-3d4751570818/Untitled.png)

모든 예측기가 훈련을 마치면 이 앙상블은 배깅이나 페이스팅과 비슷한 방식으로 예측을 만듭니다. 하지만 가중치가 적용된 훈련 세트의 전반적인 정확도에 따라 예측기마다 다른 가중치가 적용됩니다.

에이다부스트 알고리즘을 더 자세히 들여다 보겠습니다. 각 샘플 가중치 $w^{(i)}$는 초기에 $\frac{1}{m}$로 초기화 됩니다. 첫 번째 예측기가 학습되고, 가중치가 적용된 에러율 $r_1$이 Training Set에 대해 계산됩니다.

$j$번째 예측기의 가중치가 적용된 에러율

$$r_j = \frac {\sum_{i=1}^{m}w^{(i)}(\hat y ^{(i)} \neq y^{(i)})} {\sum_{i=1}^{m}w^{(i)}}$$

- 여기서 $\hat y ^ {(i)} _j$는 $i$번째 샘플에 대한 $j$번째 예측기의 예측

예측기의 가중치 $\alpha _j$는 아래의 식을 사용해 계산됩니다.

$$\alpha _j = \eta log \frac{1-r_j}{r_j}$$

- 여기서 $\eta$는 학습률 하이퍼파라미터입니다. - 원래 에이다부스트 알고리즘은 학습률 하이퍼파라미터를 사용하지 않습니다.

예측기가 정확할수록 가중치가 더 높아지게 됩니다. 만약 무작위로 예측하는 정도(0.5)라면 가중치가 0에 가까울 것입니다. 그러나 그보다 나쁘면 가중치는 음수가 됩니다. 그다음 에이다부스트 알고리즘이 아래의 식을 사용해 샘플의 가중치를 업데이트합니다. 즉 잘못 분류된 샘플의 가중치가 증가됩니다.

가중치 업데이트 규칙

$$w^{(i)}=
\begin{cases}
w^{(i)}; \hat y^{(i)}_j = y^{(i)}& \\
w^{(i)}exp(\alpha _j); \hat y^{(i)}_j \neq y^{(i)}& 
\end{cases}$$

- 이때 $i=1,2,...,m$

그런 다음 모든 샘플의 가중치를 정규화합니다(즉, $\sum_{i=1}^{m} w^{(i)}$ 로 나눕니다).

마지막으로 새 예측기가 업데이트된 가중치를 사용해 훈련되고 전체 과정이 반복됩니다(새 예측기의 가중치가 계산되고 샘플의 가중치를 업데이트해서 또 다른 예측기를 훈련시키는 식입니다). 이 알고리즘은 지정된 예측기 수에 도달하거나 완벽한 예측기가 만들어지면 중지됩니다. 예측을 할 때 에이다부스트는 단순히 모든 예측기의 예측을 계산하고 예측기 가중치 $\alpha _j$를 더해 예측 결과를 만듭니다. 가중치 합이 가장 큰 클래스가 예측 결과가 됩니다.

에이다부스트 예측

$$\hat y(\mathbf x) = argmax_k \sum _{j=1}^{N} \alpha_j ;\hat y_j(\mathbf x)=k $$

사이킷런은 `SAMME` 라는 에이다부스트의 다중 클래스 버전을 사용합니다. 클래스가 두 개뿐일 때는 에이다부스트와 동일합니다. 

### Gradient Boosting

**단점:**

- 느립니다.
- 과적합(Overfitting)의 이슈가 있습니다.

에이다부스트처럼 그레이디언트 부스팅은 앙상블에 이전까지의 오차를 보정하도록 예측기를 순차적으로 추가합니다. 하지만 에이다부스트처럼 반복마다 샘플의 가중치를 수정하는 대신 **이전 예측기가 만든 잔여 오차(Residual Error)에 새로운 예측기를 학습**시킵니다. 새로운 샘플에 대한 예측을 만들려면 모든 트리의 예측을 더하면 됩니다. Gradient Boosting과 Adaboost의 가장 큰 차이점은, Gradient는 일단 하나의 초기 예측값으로 시작한다는 것입니다. 결론적으로 하나의 예측 결과값(보통 평균)을 통해서 틀린 값이 있다면 그것에 대해서 새로운 판단 방법을 만들어 나가는 방법이라고 할 수 있습니다. Adaboost가 데이터셋을 업데이트 해나간다면 Gradient Boost는 분류기 자체를 업데이트해가는 느낌으로 볼 수 있습니다.

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/4fafdadd-7f34-47dd-8391-bf2d0c16f2aa/Untitled.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/4fafdadd-7f34-47dd-8391-bf2d0c16f2aa/Untitled.png)

`learning_rate` 매개변수가 각 트리의 기여 정도를 조절합니다. 이를 `0.1` 처럼 낮게 설정하면 앙상블을 훈련 세트에 훈련시키기 위해 많은 트리가 필요하지만 일반적으로 예측의 성능은 좋아집니다. 이는 **축소(Shrinkage)**라고 부르는 규제 방법입니다. 최적의 트리 수를 찾기 위해서는 조기 종료 기법을 사용할 수 있습니다. 간단하게 구현하려면 `staged_predict()` 를 사용합니다. 이 메서드는 훈련의 각 단계에서 앙상블에 의해 만들어진 예측기를 순회하는 반복자(Iterator)를 반환합니다. 

각 트리가 훈련할 때 사용할 훈련 샘플의 비율을 지정할 수 있는 `subsample` 매개변수도 지원합니다. 편향이 높아지는 대신 분산이 낮아지게 됩니다. 또한 훈련 속도를 상당히 높입니다. 이런 기법을 **확률적 그레이디언트 부스팅(Stochastic Gradient Boosting)**이라고 합니다. 

### **XGBOOST**

Gradient boosting 알고리즘의 단점을 보완하여 등장하였습니다.

- `GBM` 보다는 빠릅니다.
- 과적합 방지가 가능한 규제가 포함되어 있습니다.
- `CART` 기반으로 분류와 회귀 둘 다 가능합니다.
- 조기 종료(Early Stopping)을 지원합니다.

최적화된 그레이디언트 부스팅 구현으로 XGBoost 파이썬 라이브러리가 유명합니다. 이 패키지의 목표는 매우 빠른 속도, 확장성, 이식성입니다. 

## MIF:

[Ensemble methods: bagging, boosting and stacking](https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205)